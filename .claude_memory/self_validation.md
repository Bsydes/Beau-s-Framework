# Beau's Framework - Self-Validation Protocol

**Created:** 2026-01-18
**Purpose:** Use the framework's own capabilities to validate its integration health

---

## ğŸ¯ Validation Strategy

The framework validates itself using **recursive self-testing** - each component uses the system's own patterns to verify functionality.

### Validation Levels

1. **L1 - Component Health** (each piece works independently)
2. **L2 - Integration Points** (components work together)
3. **L3 - Workflow Validation** (end-to-end scenarios)
4. **L4 - Meta-Validation** (system validates its validators)

---

## ğŸ§ª Self-Check Workflow (Run This!)

### Simple Self-Check (5 minutes)

Ask Claude Code in a new session:

```
Run a comprehensive self-check of Beau's Framework. Use:
1. EXPLORER pattern to map memory structure
2. RESEARCHER pattern to verify ephor delegation works
3. THINKER pattern for analyzing integration health
4. Test /brainstorm, /write, /execute plugins
5. Log results to historian

Show me what's working and what needs attention.
```

**What happens:**
- Claude uses EXPLORER to read `~/.claude_memory/_CONTENTS.md`
- Uses RESEARCHER to call `research "test query"`
- Uses THINKER to call `think "analyze framework integration"`
- Tests plugin availability with `/help`
- Logs completion to historian

### Full Self-Validation (15 minutes)

Ask Claude Code:

```
Use /planning-with-files to create a comprehensive validation plan for Beau's Framework, then execute it using /ralph-loop with max 10 iterations. Test all four patterns (EXPLORER, RESEARCHER, THINKER, HISTORIAN), all plugins (/brainstorm, /write, /execute), and ephor delegation. Log all findings to historian under 'validation/self-check'.
```

**What happens:**
- MANUS creates planning files (task_plan.md, findings.md)
- RALPH autonomously executes validation tests
- Each pattern validates itself recursively
- Results logged to memory tree
- Final report generated

---

## ğŸ“‹ Specific Test Scenarios

### Test 1: Pattern Validation (GSD Brain)

**Command:**
```
Test each GSD pattern by using them to validate themselves:
- EXPLORER: Map the memory tree structure
- RESEARCHER: Research "Claude Code plugin best practices 2026"
- THINKER: Analyze the framework's own architecture
- HISTORIAN: Log this validation to memory

Show which patterns executed and their outputs.
```

**Expected Output:**
- âœ… Announces "Exploring codebase structure first..."
- âœ… Calls `analyze "..."` for EXPLORER
- âœ… Calls `research "..."` for RESEARCHER
- âœ… Calls `think "..."` for THINKER
- âœ… Calls `historian.py` for HISTORIAN
- âœ… All commands succeed

**Failure Indicators:**
- âŒ Patterns not announced
- âŒ Ephor commands fail
- âŒ Historian alias broken

### Test 2: Plugin Integration (Superpowers + Anthropic)

**Command:**
```
Use /brainstorm to design a simple feature, then /write to spec it, then show me the outputs. Don't actually implement, just test the workflow.
```

**Expected Output:**
- âœ… `/brainstorm` generates ideas
- âœ… `/write` creates spec document
- âœ… No errors in plugin execution

**Failure Indicators:**
- âŒ Plugins not found
- âŒ Commands don't execute
- âŒ Error messages about missing plugins

### Test 3: RALPH Autonomous Execution

**Command:**
```
Use /ralph-loop to autonomously analyze the ~/.claude_memory/ structure and create a summary report. Max 5 iterations. Completion promise: <DONE>Report created</DONE>
```

**Expected Output:**
- âœ… RALPH iterates (1-5 times)
- âœ… Creates summary report
- âœ… Stops when completion promise met
- âœ… No runaway iterations

**Failure Indicators:**
- âŒ RALPH doesn't start
- âŒ Doesn't stop at completion
- âŒ Exceeds max iterations

### Test 4: Ephor Delegation (Token Conservation)

**Command:**
```
Explain the architectural trade-offs between microservices and monoliths in 3+ paragraphs. Follow your auto-delegation rules.
```

**Expected Output:**
- âœ… Announces "ğŸ¤– Task requires [research/analysis]"
- âœ… States "ğŸ’¡ Delegating to ephor to preserve tokens"
- âœ… Calls `think` or `research` or `analyze`
- âœ… Returns ephor's response

**Failure Indicators:**
- âŒ Writes 3+ paragraphs directly (wasting tokens)
- âŒ Doesn't announce delegation
- âŒ Ephor command fails

### Test 5: Historian Memory Logging

**Command:**
```
Log a test entry to memory using: historian 'validation/framework-test' 'Self-Check Complete' 'All systems validated at [timestamp]'

Then verify it appears in the memory tree.
```

**Expected Output:**
- âœ… Command executes via Bash tool
- âœ… Success message shown
- âœ… Entry appears in `~/.claude_memory/validation/`
- âœ… `_CONTENTS.md` updated recursively

**Failure Indicators:**
- âŒ Historian alias not found
- âŒ Wrong file path used
- âŒ Index not updated

### Test 6: Subagent Recommendation (Auto-Advisor)

**Command:**
```
I have a performance issue with my React app. What should I do?
```

**Expected Output:**
- âœ… Announces "ğŸ“‹ Task Analysis: Performance optimization"
- âœ… Recommends `performance-optimizer` subagent
- âœ… Offers to install it
- âœ… Explains what it does

**Failure Indicators:**
- âŒ No subagent recommendation
- âŒ Doesn't mention VoltAgent marketplace
- âŒ Just gives generic advice

### Test 7: Integration Health (End-to-End)

**Command:**
```
Create a test project validation workflow:
1. /brainstorm a simple todo app
2. research "React best practices 2026" via ephor
3. /write a technical spec
4. Create a ROADMAP.md using /planning-with-files
5. Log completion to historian

Execute this workflow and show me each step.
```

**Expected Output:**
- âœ… All 5 steps execute in sequence
- âœ… Each pattern/plugin announces itself
- âœ… No integration conflicts
- âœ… Final log entry created

**Failure Indicators:**
- âŒ Steps fail or skip
- âŒ Plugins conflict
- âŒ Workflow breaks mid-execution

---

## ğŸ” Integration Health Checklist

After running tests, verify:

### Critical Files
- [ ] `~/.zshrc` has correct historian alias (line 9)
- [ ] `~/.claude_memory/historian.py` has both functions (save_snapshot + save_checkpoint)
- [ ] `~/CLAUDE.md` has plugin integration section
- [ ] `~/.claude/QUICK-REFERENCE.md` exists and is comprehensive

### Aliases & Commands
- [ ] `historian 'test' 'msg' 'content'` works in terminal
- [ ] `think "query"` routes to ephor
- [ ] `research "query"` routes to ephor
- [ ] `analyze "query"` routes to ephor

### Plugins Installed
- [ ] `/create-prd` available
- [ ] `/create-tech-spec` available
- [ ] `/create-test-plan` available
- [ ] `/brainstorm` available
- [ ] `/write` available
- [ ] `/execute` available
- [ ] `/ralph-loop` available
- [ ] `/planning-with-files` available

### Patterns Execute
- [ ] EXPLORER announces and uses `analyze`
- [ ] RESEARCHER announces and uses `research`
- [ ] THINKER announces and uses `think`
- [ ] HISTORIAN logs to memory tree

### Auto-Behaviors
- [ ] Auto-delegates research tasks to ephor
- [ ] Auto-recommends subagents when applicable
- [ ] Auto-announces which pattern is being used
- [ ] Auto-logs significant completions

---

## ğŸ“Š Self-Validation Report Template

After running tests, create this report:

```markdown
# Framework Validation Report
**Date:** [timestamp]
**Validator:** Claude Code (self-validation)

## Test Results

### L1 - Component Health
- GSD Patterns: âœ…/âŒ
- RALPH Loop: âœ…/âŒ
- MANUS Planning: âœ…/âŒ
- Plugins: âœ…/âŒ
- Ephor Delegation: âœ…/âŒ
- Historian: âœ…/âŒ

### L2 - Integration Points
- GSD â†” Ephor: âœ…/âŒ
- GSD â†” Plugins: âœ…/âŒ
- Plugins â†” Historian: âœ…/âŒ
- RALPH â†” MANUS: âœ…/âŒ

### L3 - Workflow Validation
- Simple task (1 pattern): âœ…/âŒ
- Complex task (2+ patterns): âœ…/âŒ
- Full lifecycle (/brainstorm â†’ /write â†’ /execute): âœ…/âŒ
- Autonomous execution (RALPH): âœ…/âŒ

### L4 - Meta-Validation
- Self-check uses its own patterns: âœ…/âŒ
- No circular dependencies: âœ…/âŒ
- Error handling works: âœ…/âŒ

## Issues Discovered
[List any failures or warnings]

## Recommendations
[Suggest fixes or improvements]

## Logged To Memory
`~/.claude_memory/validation/self-check/[timestamp]_report.md`
```

---

## ğŸš€ Quick Start: Run Self-Check Now

**Easiest way:** Open a new Claude Code window and ask:

```
Show me the self-validation protocol from ~/.claude_memory/self_validation.md, then execute Test 1 (Pattern Validation) to verify the framework is working.
```

Claude will:
1. Read this file (EXPLORER pattern)
2. Execute Test 1 using all patterns
3. Show you the results
4. Log completion to memory

**Next level:** After Test 1 passes, run Tests 2-7 sequentially.

**Full validation:** Use RALPH to run all tests autonomously:

```
Use /ralph-loop to execute all 7 self-validation tests from ~/.claude_memory/self_validation.md. Max 10 iterations. Log results to historian.
```

---

## ğŸ’¡ What Success Looks Like

When the framework is **fully integrated and working**, you'll see:

1. **Automatic announcements**: Claude says "Exploring..." / "Researching..." before acting
2. **Ephor delegation**: Long explanations are routed to `think`/`research`/`analyze`
3. **Plugin usage**: `/brainstorm`, `/write`, `/execute` work seamlessly
4. **Memory logging**: Significant completions appear in `~/.claude_memory/`
5. **Subagent recommendations**: Claude suggests specialists when appropriate
6. **No manual prompting**: You never have to remind Claude to follow patterns

If you don't see these behaviors, re-run the validation and check the failures.

---

## ğŸ”„ Continuous Validation

**Daily Health Check:**
```
Quick framework health check: verify patterns, test one plugin, confirm ephor delegation. 2 minutes.
```

**Weekly Deep Dive:**
```
Full self-validation using all 7 tests. Generate report. Log to memory.
```

**After Changes:**
```
Run integration tests after modifying CLAUDE.md, historian.py, or installing new plugins.
```

---

**Remember:** The framework is designed to maintain itself. Trust the auto-orchestration, use the patterns, let RALPH handle iterations, and log learnings to memory. The system gets smarter as you use it.
